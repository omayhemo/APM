---
name: ai-prompt
description: Sequential AI prompt creation with guided methodology with parallel execution option
metadata:
  version: 2.0.0
  agent: Product Owner
  parallel_support: true
  modes: [sequential, parallel]
---

## ðŸŽ­ PERSONA CONTEXT ACTIVATION

**This command requires the Product Owner persona.**

```markdown
*Loading Product Owner context for ai-prompt...*

Quick Context Load (1-2 seconds):
- Loading Product Owner configuration and expertise
- Loading relevant templates and frameworks
- PARALLEL_MODE: Preparing parallel execution framework
- SEQUENTIAL_MODE: Standard context loading
- Workspace validation: Ensuring execution from /mnt/c/Code/agentic-persona-mapping

*Context ready. Choose execution mode...*
```

## Command Overview

This command supports both sequential and parallel execution:

**Sequential Mode (Default):**
- Focused, guided methodology with deep analysis
- Interactive stakeholder engagement
- Systematic validation and documentation
- Quality-focused approach

**Parallel Mode (--parallel flag):**
- Multiple native sub-agents working simultaneously  
- 75% performance improvement
- Comprehensive parallel coverage
- Speed-optimized execution

## Usage

```
/ai-prompt [--parallel]
```

**Parameters:**
- `--parallel`: Execute with parallel sub-agents for faster completion
- Default: Sequential execution with guided methodology

## SEQUENTIAL_MODE: Sequential Process

```
/ai-prompt
```

## Prerequisites

Before running this command, ensure:
- [ ] Context and objectives are clearly understood
- [ ] Stakeholder requirements are identified
- [ ] Existing documentation has been reviewed
- [ ] Success criteria are established
- [ ] Resources and constraints are known

## ðŸš€ INITIALIZATION PROTOCOL (MANDATORY)

**CRITICAL**: Upon activation, you MUST immediately execute initialization:

```
I'm launching sequential ai-prompt for comprehensive development and analysis.

*Loading ai-prompt templates and methodologies...*
[Execute initialization tasks in sequence]
- Load ai-prompt templates and frameworks
- Review context and requirements
- Prepare systematic methodology
- Set up validation and documentation processes
```

## Sequential Ai-prompt Process

### Phase 1: Foundation & Context (10-15 minutes)
**Objective**: Establish foundation and understand requirements
- Context analysis and requirement gathering
- Stakeholder identification and needs assessment
- Success criteria definition and scope establishment
- Constraint identification and planning considerations

### Phase 2: Development & Analysis (20-30 minutes) 
**Objective**: Execute core ai-prompt activities
- Systematic development following proven methodologies
- Interactive refinement and stakeholder engagement
- Quality validation and completeness checking
- Iterative improvement based on feedback

### Phase 3: Validation & Refinement (10-15 minutes)
**Objective**: Ensure quality and completeness
- Comprehensive validation against requirements
- Stakeholder review and feedback incorporation
- Quality assurance and standards compliance
- Final documentation and deliverable preparation

## Expected Outcomes

After ai-prompt completion:
- **Comprehensive deliverables** meeting all requirements
- **Quality assurance** with validation completed
- **Stakeholder alignment** with approval obtained
- **Clear documentation** with rationale and decisions
- **Implementation readiness** with next steps defined

## Output Format

```markdown
# Ai-prompt Results

## Overview
- **Ai-prompt Type**: [Type/Category]
- **Agent**: Designer
- **Completion Date**: [Date]
- **Status**: [Complete/In Progress]

## Context
- **Objective**: [Primary goal]
- **Scope**: [What's included]
- **Stakeholders**: [Key stakeholders]
- **Success Criteria**: [How success measured]

## Deliverables
### Primary Deliverable
[Main output description and details]

### Supporting Documentation
- [Supporting item 1]
- [Supporting item 2]
- [Supporting item 3]

## Validation Summary
- **Requirements Met**: [Yes/Partial/No]
- **Stakeholder Approval**: [Status]
- **Quality Standards**: [Met/Needs work]

## Next Steps
1. [Immediate next action]
2. [Follow-up activities]
3. [Implementation planning]
```

## Integration Points

- **Requirements**: Use `/planning-requirements` for detailed analysis
- **Planning**: Use `/planning-epic` or `/planning-prd` for comprehensive planning
- **Validation**: Use `/planning-stakeholder-review` for validation
- **Implementation**: Use parallel versions for rapid execution

## Voice Notifications

```bash
bash /mnt/c/Code/agentic-persona-mapping/.apm/agents/voice/speakDesigner.sh "Sequential ai-prompt beginning. Launching guided development process..."
```

## Success Metrics

- **Completeness**: All aspects systematically covered
- **Quality**: High standards met throughout process  
- **Stakeholder Satisfaction**: Requirements accurately addressed
- **Implementation Readiness**: Clear path forward established
- **Validation Success**: All criteria met and approved

## When to Use Sequential vs Parallel

**Use `/ai-prompt` when:**
- Focused development with single deliverable
- Interactive refinement and collaboration desired
- Quality and thoroughness over speed
- Complex requirements need careful analysis
- Stakeholder engagement throughout process important

**Use `/parallel-ai-prompt` when:**
- Multiple deliverables needed simultaneously
- Time constraints require rapid execution
- Comprehensive coverage across domains
- Well-understood process and templates
- Speed and efficiency prioritized

---

This command provides thoughtful, systematic ai-prompt with emphasis on quality, stakeholder collaboration, and comprehensive coverage.

## PARALLEL_MODE: Parallel Process
## ðŸš€ INITIALIZATION PROTOCOL (MANDATORY)

**CRITICAL**: Upon activation, you MUST immediately execute parallel initialization:

```
I'm initializing the Parallel AI Prompt Generation process. Let me load all required context in parallel for optimal performance.

*Executing parallel initialization tasks:*
[Execute all 5 tasks in single function_calls block]
- Task 1: Load AI prompt standards from /mnt/c/Code/agentic-persona-mapping/.apm/agents/templates/ai-prompt-standards.md
- Task 2: Load current AI documentation from /mnt/c/Code/agentic-persona-mapping/project_docs/ai/
- Task 3: Load use case requirements from /mnt/c/Code/agentic-persona-mapping/project_docs/planning-requirements/
- Task 4: Load prompt patterns from /mnt/c/Code/agentic-persona-mapping/.apm/agents/templates/prompt-patterns.md
- Task 5: Load AI model specifications from /mnt/c/Code/agentic-persona-mapping/.apm/agents/templates/ai-model-specs.md
```

## Parallel Prompt Generation Streams

### Stream 1: System & Role Prompt Architecture (8-12 minutes)
- **Focus**: System prompts, role definitions, persona establishment, behavioral guidelines
- **Deliverables**: System prompt templates, role definitions, persona frameworks
- **Dependencies**: Business objectives, AI model capabilities, use case requirements
- **Integration**: Cross-prompt consistency, role hierarchy, behavioral alignment

### Stream 2: Task-Specific Prompt Engineering (10-15 minutes)
- **Focus**: Domain-specific prompts, task automation, workflow integration
- **Deliverables**: Task prompt libraries, workflow automations, integration patterns
- **Dependencies**: Specific use cases, workflow requirements, output formats
- **Integration**: System prompts, data flow, error handling

### Stream 3: Context & Memory Management (12-18 minutes)
- **Focus**: Context optimization, memory strategies, conversation management
- **Deliverables**: Context frameworks, memory patterns, conversation architectures
- **Dependencies**: Conversation flow, data persistence, performance constraints
- **Integration**: Prompt continuity, state management, conversation threading

### Stream 4: Quality Control & Testing Framework (8-14 minutes)
- **Focus**: Prompt validation, A/B testing, performance monitoring, quality metrics
- **Deliverables**: Testing frameworks, quality metrics, validation pipelines
- **Dependencies**: Quality standards, testing requirements, monitoring capabilities
- **Integration**: Prompt versioning, performance tracking, continuous improvement

## Native Implementation Architecture

This command uses native sub-agent parallelism to spawn Designer AI specialists:

### Phase 1: AI Context Loading (5 tasks in parallel)
1. **Load AI Prompt Standards**: Best practices and prompt engineering principles
2. **Analyze Current AI Systems**: Existing AI implementations and constraints
3. **Extract Use Case Requirements**: Business objectives and AI application needs
4. **Load Prompt Patterns**: Proven prompt templates and successful patterns
5. **Load AI Model Specifications**: Model capabilities, limitations, and optimizations

### Phase 2: Native Stream Agent Spawning
6. **Spawn System Prompt Agent**: Role definition and system behavior specialist
7. **Spawn Task Prompt Agent**: Domain-specific and workflow integration specialist
8. **Spawn Context Management Agent**: Memory and conversation architecture specialist
9. **Spawn Quality Control Agent**: Testing and validation framework specialist

### Phase 3: Real-Time Coordination
10. **Monitor Integration Points**: Track prompt consistency and behavioral alignment
11. **Coordinate Dependencies**: Facilitate handoffs between prompt development streams
12. **Synthesize Framework**: Aggregate results into unified AI prompt architecture
13. **Update Documentation**: Real-time updates to AI prompt documentation and guidelines

## Expected Outcomes

- **Parallel Prompt Streams**: 4 Designer AI agents working simultaneously
- **Coordinated Framework**: Seamless integration of all AI prompt development aspects
- **Accelerated Development**: 75% reduction in sequential prompt development time
- **Quality Assurance**: Built-in testing and validation frameworks
- **Production Readiness**: Comprehensive AI prompt libraries ready for deployment

## Parallel Development Benefits

- **Specialized Expertise**: Focused development on each AI prompt domain
- **Reduced Development Time**: Parallel creation of prompt frameworks
- **Better Integration**: Proactive coordination prevents prompt conflicts
- **Quality Focus**: Dedicated testing and validation stream
- **Scalable Architecture**: Reusable prompt patterns and frameworks

## Output Format

```markdown
# AI Prompt Architecture - Parallel Execution Results

## Framework Overview
- Target AI Models: [GPT-4/Claude/Gemini/Multiple]
- Prompt Architecture: [Hierarchical/Flat/Modular]
- Integration Method: [API/SDK/Custom/Hybrid]

## Stream Results Summary

### 1. System & Role Prompt Architecture
- System Prompts: [N] role definitions
- Persona Framework: [Complete/Partial/Planned]
- Behavioral Guidelines: [N] behavioral patterns
- **Status**: âœ… Complete / ðŸ”„ In Progress / âš ï¸ Blocked

### 2. Task-Specific Prompt Engineering
- Task Prompts: [N] domain-specific prompts
- Workflow Integration: [Automated/Manual/Hybrid]
- Output Formats: [N] structured formats
- **Status**: âœ… Complete / ðŸ”„ In Progress / âš ï¸ Blocked

### 3. Context & Memory Management
- Context Strategy: [Sliding-window/Summarization/Retrieval]
- Memory Patterns: [N] conversation patterns
- State Management: [Stateless/Stateful/Hybrid]
- **Status**: âœ… Complete / ðŸ”„ In Progress / âš ï¸ Blocked

### 4. Quality Control & Testing Framework
- Testing Coverage: [Unit/Integration/E2E prompts]
- Quality Metrics: [N] performance indicators
- Validation Pipeline: [Automated/Manual/Hybrid]
- **Status**: âœ… Complete / ðŸ”„ In Progress / âš ï¸ Blocked

## Prompt Integration Matrix
[Cross-stream prompt dependencies and consistency requirements]

## Architecture Decisions
[Key AI prompt architectural decisions with reasoning]

## Performance Targets
- Response Quality: [Target accuracy/relevance scores]
- Response Time: [Target latency requirements]
- Token Efficiency: [Target token usage optimization]
- Error Rate: [Target error/fallback rates]

## Prompt Libraries
### System Prompts
- Role-based prompts for different AI personas
- Behavioral guidelines and constraint enforcement
- Context-aware system instructions

### Task Prompts
- Domain-specific workflow automation
- Structured output generation
- Error handling and validation

### Context Management
- Conversation threading and memory
- Context compression and summarization
- State preservation patterns

### Testing Framework
- Prompt validation and A/B testing
- Performance monitoring and analytics
- Quality assurance and regression testing

## Next Steps
- [ ] Prompt library implementation
- [ ] Integration testing with target AI models
- [ ] Performance optimization and tuning
- [ ] Quality metrics validation
- [ ] Production deployment preparation
```

## Workflow Steps

1. **Context Loading**: Load all AI prompt context in parallel (5 tasks)
2. **Stream Analysis**: Analyze requirements for each prompt development domain
3. **Agent Spawning**: Launch 4 specialized Designer AI agents
4. **Parallel Execution**: Execute all streams simultaneously with coordination
5. **Integration Monitoring**: Track dependencies and prompt consistency
6. **Results Synthesis**: Aggregate all stream results into unified AI framework
7. **Documentation Update**: Update AI prompt documentation with results
8. **Validation**: Validate prompt effectiveness and integration completeness

## Performance Metrics

- **Baseline Development Time**: 40-55 minutes (sequential)
- **Parallel Development Time**: 10-14 minutes (parallel streams)
- **Performance Improvement**: 75% faster execution
- **Stream Coverage**: 100% comprehensive AI prompt coverage
- **Integration Success**: >90% successful cross-stream prompt alignment

## Integration Points

- **Product Owner**: Provides business objectives and AI use case requirements
- **Developer Agents**: Receives AI prompt frameworks and integration guidance
- **QA Agent**: Gets AI testing frameworks and quality validation strategies
- **System Architect**: Coordinates with backend systems and AI model integration

## Available Capabilities

- **System Prompt Design**: Role-based AI personas and behavioral frameworks
- **Task Automation**: Domain-specific prompt engineering and workflow integration
- **Context Architecture**: Memory management and conversation threading
- **Quality Framework**: Testing, validation, and performance monitoring
- **Prompt Optimization**: Token efficiency and response quality improvement
- **Integration Patterns**: API integration and deployment strategies
- **Documentation**: Comprehensive prompt libraries and usage guidelines
- **A/B Testing**: Prompt performance comparison and optimization

## Success Metrics

- **Streams Completed in Parallel**: Target 4 simultaneous development streams
- **Prompt Quality**: >85% accuracy/relevance in target use cases
- **Development Velocity**: 75% improvement over sequential development
- **Integration Success Rate**: >90% successful AI model integration
- **Performance Efficiency**: Optimal token usage and response times

## Voice Notifications

```bash
bash /mnt/c/Code/agentic-persona-mapping/.apm/agents/voice/speakDesigner.sh "Parallel AI prompt generation launching. Initiating 4 simultaneous development streams for 75% AI prompt acceleration..."
```

## Native Sub-Agent Activation

When you run `/parallel-ai-prompt`, I will:

1. **AI Context**: Load all prompt standards and current AI implementations
2. **Stream Allocation**: Launch 4 specialized design architect AI agents
3. **Natural Language Spawning**: Activate each agent with specific AI context:

```markdown
# System Prompt Agent Activation:
"I need an AI System Prompt specialist to design role-based prompts.
 AI Context:
 - Business Objectives: [Primary AI use cases and success criteria]
 - Target Models: [GPT-4, Claude, or specific AI model capabilities]
 - Focus Areas: Role definitions, persona establishment, behavioral guidelines
 - Integration Points: Cross-prompt consistency, role hierarchy alignment
 - Deliverables: System prompt templates, role frameworks, persona definitions
 Please design comprehensive system prompts following AI best practices."

# Task Prompt Agent Activation:
"I need a Task-Specific Prompt specialist to design workflow automation.
 AI Context:
 - Use Cases: [Specific business workflows and automation requirements]
 - Output Requirements: [Structured formats and integration needs]
 - Focus Areas: Domain-specific prompts, task automation, workflow integration
 - Integration Points: System prompt compatibility, data flow optimization
 - Deliverables: Task prompt libraries, automation workflows, integration patterns
 Please design efficient task-specific prompt frameworks."
```

4. **Real-Time Coordination**: Monitor progress, facilitate prompt integration
5. **Results Synthesis**: Aggregate comprehensive AI prompt architecture

## Advanced Configuration

```yaml
# parallel-ai-prompt-config.yaml
parallel_ai_prompt:
  streams: 4
  max_parallel_streams: 6
  stream_timeout: 18  # minutes
  
  coordination:
    prompt_consistency_monitoring: true
    integration_tracking: true
    real_time_synthesis: true
    
  output:
    detailed_prompt_specs: true
    testing_frameworks: true
    integration_guidance: true
    performance_optimization: true
```

## Example AI Prompt Templates

### System Role Prompt
```
You are a [ROLE] with expertise in [DOMAIN].

Your primary responsibilities:
- [Responsibility 1]
- [Responsibility 2]
- [Responsibility 3]

Behavioral Guidelines:
- Always [Guideline 1]
- Never [Constraint 1]
- When uncertain, [Fallback behavior]

Output Format: [Specify structured format]
Quality Standards: [Define success criteria]
```

### Task-Specific Prompt
```
Task: [SPECIFIC_TASK]
Context: [RELEVANT_CONTEXT]
Requirements: [SPECIFIC_REQUIREMENTS]

Input Format:
[Define expected input structure]

Processing Instructions:
1. [Step 1]
2. [Step 2]
3. [Step 3]

Output Requirements:
[Define expected output format and validation]
```

---
*Part of the APM High-Performance AI Development Infrastructure*
